{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c115a3b",
   "metadata": {},
   "source": [
    "# テーマD：量子化-多層分解同時実行時における深さとビット幅の最適比\n",
    "[Open In Colab](https://colab.research.google.com/github/ArtIC-TITECH/b3-proj-2025/blob/main/theme_D/theme_D.ipynb)\n",
    "\n",
    "## モジュールの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1913299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Function\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2a50a",
   "metadata": {},
   "source": [
    "## MNISTのデータセット/精度評価関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5279c324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.38MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 176kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 1.65MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.04MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 実行デバイスの設定\n",
    "device = 'cuda:2'\n",
    "\n",
    "# 普通のtransform\n",
    "transform_normal = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# テストデータには普通のtransformを使ってください\n",
    "transform_for_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_normal) # モデルの学習に使うデータセット\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_for_test) # モデルの評価に使うデータセット\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def compute_accuracy(model, test_loader, device='cuda:0'):\n",
    "    model.eval()  # 評価モード\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "def train(model, lr=0.05, epochs=5, device='cuda:0'):\n",
    "    # 損失関数と最適化手法の定義\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0\n",
    "        for images, labels in train_loader:\n",
    "            # モデルの予測\n",
    "            outputs = model(images.to(device))\n",
    "\n",
    "            # 損失の計算\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            # 勾配の初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            loss.backward()\n",
    "\n",
    "            # オプティマイザの更新\n",
    "            optimizer.step()\n",
    "\n",
    "        # 損失を表示\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss_sum/len(train_loader):.4f}')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e723368",
   "metadata": {},
   "source": [
    "\n",
    "## 通常モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c72c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self): # モデルのセットアップ\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 24)\n",
    "        self.fc2 = nn.Linear(24, 10)\n",
    "\n",
    "    def forward(self, x): # モデルが行う処理\n",
    "        x = x.view(-1, 28 * 28)  # 28x28の画像を１次元に変換\n",
    "        x = self.fc1(x) \n",
    "        x = nn.ReLU()(x) # 活性化関数\n",
    "        x = self.fc2(x) \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5ee88",
   "metadata": {},
   "source": [
    "精度の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8317e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.56%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = SimpleModel().to(device)\n",
    "model = train(model, lr=0.1, epochs=10, device=device)\n",
    "accuracy = compute_accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1d36f",
   "metadata": {},
   "source": [
    "## スカラー量子化（一様対称量子化）の実行\n",
    "\n",
    "###  プロセス：量子化層に変換-->量子化認識学習\n",
    "\n",
    "ここでは簡便に量子化パラメータをmin-maxスケーリングで決定する\n",
    "対称量子化なので、行列Xの最大値と最小値の差の２分の1を$p$-bitの数値範囲の最大値$q_{max}$でわる\n",
    "\n",
    "$q_{max} = 2^{(p-1)} - 1$\n",
    "\n",
    "$s = \\frac{max(X) - min(X)}{2q_{max}}$\n",
    "\n",
    "$X_{q} = s * \\text{clip}(\\text{round}(\\frac{X}{s}), -q_{max}, q_{max})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df401a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SymQuantSTE(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input: torch.Tensor, scale: torch.Tensor, num_bits: int):\n",
    "        if num_bits == 1:\n",
    "            s = scale.abs()\n",
    "            output = s * torch.sgn(input)\n",
    "        else:\n",
    "            s = scale.abs().clamp_min(1e-8)\n",
    "            qmax = 2 ** (num_bits - 1) - 1\n",
    "            q = torch.clamp(torch.round(input / s), -qmax, qmax)\n",
    "            output = q * s\n",
    "\n",
    "        # backward用に保存\n",
    "        ctx.save_for_backward(input, s)\n",
    "        ctx.num_bits = num_bits\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, s = ctx.saved_tensors   # forwardでsaveしたものを正しく取り出す\n",
    "        num_bits = ctx.num_bits\n",
    "        if num_bits == 1:\n",
    "            mask = (input.abs() <= s).to(grad_output.dtype)\n",
    "            grad_input = grad_output * mask\n",
    "        else:\n",
    "            qmax = 2 ** (num_bits - 1) - 1\n",
    "            mask = (input.abs() <= qmax * s).to(grad_output.dtype)\n",
    "            grad_input = grad_output * mask\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SymQuantLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True, weight_bits=8, act_bits=None):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.weight_bits = weight_bits\n",
    "        self.act_bits = act_bits\n",
    "\n",
    "    def forward(self, input):\n",
    "        # weight のスケール\n",
    "        if self.weight_bits == 1:\n",
    "            weight_scale = self.weight.abs().sum() / self.weight.numel()\n",
    "        else:\n",
    "            qmax_w = 2 ** (self.weight_bits - 1) - 1\n",
    "            weight_scale = (self.weight.max() - self.weight.min()) / (2 * qmax_w)\n",
    "\n",
    "        # activation のスケール\n",
    "        if self.act_bits is not None:\n",
    "            if self.act_bits == 1:\n",
    "                act_scale = input.abs().sum() / input.numel()\n",
    "            else:\n",
    "                qmax_a = 2 ** (self.act_bits - 1) - 1\n",
    "                act_scale = (input.max() - input.min()) / (2 * qmax_a)\n",
    "            input = SymQuantSTE.apply(input, act_scale, self.act_bits)\n",
    "\n",
    "        # quantized weight\n",
    "        w_q = SymQuantSTE.apply(self.weight, weight_scale, self.weight_bits)\n",
    "\n",
    "        return F.linear(input, w_q, self.bias)\n",
    "\n",
    "\n",
    "\n",
    "def replace_linear_with_quantizedlinear(module, weight_bits=8, act_bits=None):\n",
    "    for name, child in module.named_children():\n",
    "        # すでに QuantizedLinear ならスキップ\n",
    "        if isinstance(child, SymQuantLinear):\n",
    "            qlinear = SymQuantLinear(\n",
    "                child.in_features,\n",
    "                child.out_features,\n",
    "                bias=(child.bias is not None),\n",
    "                weight_bits=weight_bits,\n",
    "                act_bits=act_bits\n",
    "            )\n",
    "            # 重みとバイアスをコピー\n",
    "            qlinear.weight.data.copy_(child.weight.data)\n",
    "            if child.bias is not None:\n",
    "                qlinear.bias.data.copy_(child.bias.data)\n",
    "            setattr(module, name, qlinear)\n",
    "        if isinstance(child, nn.Linear):\n",
    "            qlinear = SymQuantLinear(\n",
    "                child.in_features,\n",
    "                child.out_features,\n",
    "                bias=(child.bias is not None),\n",
    "                weight_bits=weight_bits,\n",
    "                act_bits=act_bits\n",
    "            )\n",
    "            # 重みとバイアスをコピー\n",
    "            qlinear.weight.data.copy_(child.weight.data)\n",
    "            if child.bias is not None:\n",
    "                qlinear.bias.data.copy_(child.bias.data)\n",
    "            setattr(module, name, qlinear)\n",
    "        else:\n",
    "            replace_linear_with_quantizedlinear(child, weight_bits, act_bits)\n",
    "    return module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのインスタンスを作成\n",
    "model = SimpleModel().to(device)\n",
    "# 通常学習\n",
    "print('warming up by no-quantized training...')\n",
    "model = train(model, lr=0.1, epochs=5, device=device)\n",
    "# Linear層をQuantizedLinearに置換\n",
    "model_q = replace_linear_with_quantizedlinear(model, weight_bits=1, act_bits=None)\n",
    "print('quantization aware training...')\n",
    "model_q = train(model_q, lr=1e-2, epochs=10, device=device)\n",
    "accuracy = compute_accuracy(model_q, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0da6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomposedLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, depth=3, bias=True):\n",
    "        super().__init__()\n",
    "        assert depth >= 1, \"depth must be >= 2\"\n",
    "\n",
    "        # 中間次元 l を計算\n",
    "        if depth == 2:\n",
    "            l = int(round(in_dim * out_dim / (in_dim + out_dim)))\n",
    "            dims = [in_dim, l, out_dim]\n",
    "        elif depth == 1:\n",
    "            l = min(in_dim, out_dim)\n",
    "            dims = [in_dim, out_dim]\n",
    "        else:\n",
    "            a = depth - 2\n",
    "            b = in_dim + out_dim\n",
    "            c = - in_dim * out_dim\n",
    "            l = int(round((-b + math.sqrt(b*b - 4*a*c)) / (2*a)))\n",
    "            dims = [in_dim] + [l]*(depth-1) + [out_dim]\n",
    "\n",
    "        self.l = l\n",
    "        self.depth = depth\n",
    "\n",
    "        # nn.Linear を順につなげる\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(dims[i], dims[i+1], bias=(i==depth-1 and bias))\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# --- nn.Linear をすべて DecomposedLinear に置換 ---\n",
    "def replace_linear_with_decomposedlinear(module, depth=3):\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, DecomposedLinear):\n",
    "            continue\n",
    "        if isinstance(child, nn.Linear):\n",
    "            m, n = child.in_features, child.out_features\n",
    "            dlinear = DecomposedLinear(m, n, depth=depth)\n",
    "            # バイアスは最後の層にコピー\n",
    "            if child.bias is not None:\n",
    "                dlinear.layers[-1].bias.data.copy_(child.bias.data)\n",
    "            setattr(module, name, dlinear)\n",
    "        else:\n",
    "            replace_linear_with_decomposedlinear(child, depth=depth)\n",
    "    return module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c45a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warming up by no-quantized training...\n",
      "Epoch [1/5], Loss: 0.5831\n",
      "Epoch [2/5], Loss: 0.2633\n",
      "Epoch [3/5], Loss: 0.2200\n",
      "Epoch [4/5], Loss: 0.1907\n",
      "Epoch [5/5], Loss: 0.1762\n",
      "quantization aware training...\n",
      "Epoch [1/10], Loss: 0.8134\n",
      "Epoch [2/10], Loss: 0.5061\n",
      "Epoch [3/10], Loss: 0.4639\n",
      "Epoch [4/10], Loss: 0.4582\n",
      "Epoch [5/10], Loss: 0.4344\n",
      "Epoch [6/10], Loss: 0.4179\n",
      "Epoch [7/10], Loss: 0.4139\n",
      "Epoch [8/10], Loss: 0.4184\n",
      "Epoch [9/10], Loss: 0.4200\n",
      "Epoch [10/10], Loss: 0.4149\n",
      "Accuracy: 86.96%\n"
     ]
    }
   ],
   "source": [
    "# 行列分解モデルのインスタンスを作成\n",
    "model = SimpleModel().to(device)\n",
    "model = replace_linear_with_decomposedlinear(model, depth=2)\n",
    "\n",
    "# 通常学習\n",
    "print('warming up by no-quantized training...')\n",
    "model = train(model, lr=0.1, epochs=5, device=device)\n",
    "# Linear層をDecomposedQuantizedLinearに置換\n",
    "model_q = replace_linear_with_quantizedlinear(model, weight_bits=1, act_bits=None)\n",
    "\n",
    "print('quantization aware training...')\n",
    "model_q = train(model_q, lr=1e-2, epochs=10, device=device)\n",
    "accuracy = compute_accuracy(model_q, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8a023",
   "metadata": {},
   "source": [
    "## モデルサイズの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfadf79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size: 0.07 MB\n"
     ]
    }
   ],
   "source": [
    "def compute_model_size(model: nn.Module):\n",
    "    total_size = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            # 通常の Linear 層のサイズ (float32)\n",
    "            total_size += module.weight.numel() * 4  # float32 として計算\n",
    "            if module.bias is not None:\n",
    "                total_size += module.bias.numel() * 4  # float32 として計算\n",
    "        elif isinstance(module, SymQuantLinear):\n",
    "            if module.weight_bits is None:\n",
    "                module.weight_bits = 32  # float32として計算\n",
    "            # weight のサイズ\n",
    "            total_size += module.weight.numel() * module.weight_bits/8  \n",
    "            # bias のサイズ\n",
    "            if module.bias is not None:\n",
    "                total_size += module.bias.numel() * 4  # float32 として計算\n",
    "    return total_size / (1024 * 1024)  # MB単位で返す\n",
    "\n",
    "\n",
    "model_size = compute_model_size(model_q)\n",
    "print(f'Model size: {model_size:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf083a",
   "metadata": {},
   "source": [
    "## 課題\n",
    "### ・重みをパラメータ数を変えずに行列分解して多層化したものに対し量子化をした場合、低ビット幅の状況下において深さと精度はどのような関係になるか評価する\n",
    "### ・行列分解に加えて、層間に活性化関数を挟みこむと、低ビット時の精度はどうなるかを評価する"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
