{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c115a3b",
   "metadata": {},
   "source": [
    "# テーマE：量子化と枝刈りの同時実行時のビット幅とスパーシティの最適比\n",
    "\n",
    "\n",
    "## モジュールの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1913299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c2a50a",
   "metadata": {},
   "source": [
    "## MNISTのデータセット/精度評価関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5279c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行デバイスの設定\n",
    "device = 'cuda:2'\n",
    "\n",
    "# 普通のtransform\n",
    "transform_normal = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# テストデータには普通のtransformを使ってください\n",
    "transform_for_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_normal) # モデルの学習に使うデータセット\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_for_test) # モデルの評価に使うデータセット\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "def compute_accuracy(model, test_loader, device='cuda:0'):\n",
    "    model.eval()  # 評価モード\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.to(device)).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "    return accuracy\n",
    "\n",
    "def train(model, lr=0.05, epochs=5, device='cuda:0'):\n",
    "    # 損失関数と最適化手法の定義\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        loss_sum = 0\n",
    "        for images, labels in train_loader:\n",
    "            # モデルの予測\n",
    "            outputs = model(images.to(device))\n",
    "\n",
    "            # 損失の計算\n",
    "            loss = criterion(outputs, labels.to(device))\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            # 勾配の初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # バックプロパゲーション\n",
    "            loss.backward()\n",
    "\n",
    "            # オプティマイザの更新\n",
    "            optimizer.step()\n",
    "\n",
    "        # 損失を表示\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss_sum/len(train_loader):.4f}')\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e723368",
   "metadata": {},
   "source": [
    "\n",
    "## 通常モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c72c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.4596\n",
      "Epoch [2/5], Loss: 0.1787\n",
      "Epoch [3/5], Loss: 0.1324\n",
      "Epoch [4/5], Loss: 0.1033\n",
      "Epoch [5/5], Loss: 0.0859\n"
     ]
    }
   ],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self): # モデルのセットアップ\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x): # モデルが行う処理\n",
    "        x = x.view(-1, 28 * 28)  # 28x28の画像を１次元に変換\n",
    "        x = self.fc1(x) \n",
    "        x = nn.ReLU()(x) # 活性化関数\n",
    "        x = self.fc2(x) \n",
    "        x = nn.ReLU()(x) # 活性化関数\n",
    "        x = self.fc3(x) \n",
    "        return x\n",
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = SimpleModel().to(device)\n",
    "\n",
    "model = train(model, lr=0.1, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5ee88",
   "metadata": {},
   "source": [
    "精度の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8317e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.40%\n"
     ]
    }
   ],
   "source": [
    "accuracy = compute_accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a1d36f",
   "metadata": {},
   "source": [
    "## スカラー量子化（一様対称量子化）の実行\n",
    "\n",
    "###  プロセス：量子化層に変換-->量子化認識学習\n",
    "\n",
    "ここでは簡便に量子化パラメータをmin-maxスケーリングで決定する\n",
    "対称量子化なので、行列Xの最大値と最小値の差の２分の1を$p$-bitの数値範囲の最大値$q_{max}$でわる\n",
    "\n",
    "$q_{max} = 2^{(p-1)} - 1$\n",
    "\n",
    "$s = \\frac{max(X) - min(X)}{2q_{max}}$\n",
    "\n",
    "$X_{q} = s * \\text{clip}(\\text{round}(\\frac{X}{s}), -q_{max}, q_{max})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df401a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warming up by no-quantized training...\n",
      "Epoch [1/5], Loss: 0.4444\n",
      "Epoch [2/5], Loss: 0.1771\n",
      "Epoch [3/5], Loss: 0.1291\n",
      "Epoch [4/5], Loss: 0.1031\n",
      "Epoch [5/5], Loss: 0.0871\n",
      "quantization aware training...\n",
      "Epoch [1/5], Loss: 0.0786\n",
      "Epoch [2/5], Loss: 0.0643\n",
      "Epoch [3/5], Loss: 0.0602\n",
      "Epoch [4/5], Loss: 0.0582\n",
      "Epoch [5/5], Loss: 0.0575\n",
      "Accuracy: 97.43%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class SymQuantSTE(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input: torch.Tensor, scale: torch.Tensor, num_bits: int):\n",
    "        if num_bits == 1:\n",
    "            s = scale.abs()\n",
    "            output = s * torch.sgn(input)\n",
    "        else:\n",
    "            s = scale.abs().clamp_min(1e-8)\n",
    "            qmax = 2 ** (num_bits - 1) - 1\n",
    "            q = torch.clamp(torch.round(input / s), -qmax, qmax)\n",
    "            output = q * s\n",
    "\n",
    "        # backward用に保存\n",
    "        ctx.save_for_backward(input, s)\n",
    "        ctx.num_bits = num_bits\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, s = ctx.saved_tensors   # forwardでsaveしたものを正しく取り出す\n",
    "        num_bits = ctx.num_bits\n",
    "        if num_bits == 1:\n",
    "            grad_input = torch.clamp(grad_output, -1, 1)\n",
    "        else:\n",
    "            qmax = 2 ** (num_bits - 1) - 1\n",
    "            mask = (input.abs() <= qmax * s).to(grad_output.dtype)\n",
    "            grad_input = grad_output * mask\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SymQuantLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True, weight_bits=8, act_bits=None):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.weight_bits = weight_bits\n",
    "        self.act_bits = act_bits\n",
    "\n",
    "    def forward(self, input):\n",
    "        # weight のスケール\n",
    "        if self.weight_bits == 1:\n",
    "            weight_scale = self.weight.abs().sum() / self.weight.numel()\n",
    "        else:\n",
    "            qmax_w = 2 ** (self.weight_bits - 1) - 1\n",
    "            weight_scale = (self.weight.max() - self.weight.min()) / (2 * qmax_w)\n",
    "\n",
    "        # activation のスケール\n",
    "        if self.act_bits is not None:\n",
    "            if self.act_bits == 1:\n",
    "                act_scale = input.abs().sum() / input.numel()\n",
    "            else:\n",
    "                qmax_a = 2 ** (self.act_bits - 1) - 1\n",
    "                act_scale = (input.max() - input.min()) / (2 * qmax_a)\n",
    "            input = SymQuantSTE.apply(input, act_scale, self.act_bits)\n",
    "\n",
    "        # quantized weight\n",
    "        w_q = SymQuantSTE.apply(self.weight, weight_scale, self.weight_bits)\n",
    "\n",
    "        return F.linear(input, w_q, self.bias)\n",
    "\n",
    "\n",
    "\n",
    "def replace_linear_with_quantizedlinear(module, weight_bits=8, act_bits=None):\n",
    "    for name, child in module.named_children():\n",
    "        # すでに QuantizedLinear ならスキップ\n",
    "        if isinstance(child, SymQuantLinear):\n",
    "            continue\n",
    "        if isinstance(child, nn.Linear):\n",
    "            qlinear = SymQuantLinear(\n",
    "                child.in_features,\n",
    "                child.out_features,\n",
    "                bias=(child.bias is not None),\n",
    "                weight_bits=weight_bits,\n",
    "                act_bits=act_bits\n",
    "            )\n",
    "            # 重みとバイアスをコピー\n",
    "            qlinear.weight.data.copy_(child.weight.data)\n",
    "            if child.bias is not None:\n",
    "                qlinear.bias.data.copy_(child.bias.data)\n",
    "            setattr(module, name, qlinear)\n",
    "        else:\n",
    "            replace_linear_with_quantizedlinear(child, weight_bits, act_bits)\n",
    "    return module\n",
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = SimpleModel().to(device)\n",
    "# 通常学習\n",
    "print('warming up by no-quantized training...')\n",
    "model = train(model, lr=0.1, epochs=5, device=device)\n",
    "# Linear層をQuantizedLinearに置換\n",
    "model_q = replace_linear_with_quantizedlinear(model, weight_bits=4, act_bits=4)\n",
    "print('quantization aware training...')\n",
    "model_q = train(model_q, lr=1e-3, epochs=5, device=device)\n",
    "accuracy = compute_accuracy(model_q, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785087b6",
   "metadata": {},
   "source": [
    "## 枝刈りの実行\n",
    "\n",
    "### 実行プロセス：学習過程で重みの絶対値をスコアとして、スコアが小さいtop-kを0にする(枝刈り)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ab8568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warming up by no-quantized training...\n",
      "Epoch [1/5], Loss: 0.4493\n",
      "Epoch [2/5], Loss: 0.1750\n",
      "Epoch [3/5], Loss: 0.1285\n",
      "Epoch [4/5], Loss: 0.1021\n",
      "Epoch [5/5], Loss: 0.0830\n",
      "pruning...\n",
      "Epoch [1/5], Loss: 0.2021\n",
      "Epoch [2/5], Loss: 0.1361\n",
      "Epoch [3/5], Loss: 0.1230\n",
      "Epoch [4/5], Loss: 0.1138\n",
      "Epoch [5/5], Loss: 0.1078\n",
      "Accuracy: 96.65%\n"
     ]
    }
   ],
   "source": [
    "class PrunedLinear(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True, prune_ratio=0.2):\n",
    "        \"\"\"\n",
    "        prune_ratio: 枝刈りする割合 (0.2 なら全重みの 20% を 0 にする)\n",
    "        \"\"\"\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        assert 0.0 <= prune_ratio < 1.0\n",
    "        self.prune_ratio = prune_ratio\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # weight をコピー\n",
    "        W = self.weight\n",
    "\n",
    "        if self.prune_ratio > 0:\n",
    "            # |W| を平坦化\n",
    "            flat = W.abs().flatten()\n",
    "            k = int(self.prune_ratio * flat.numel())\n",
    "            if k > 0:\n",
    "                # top-k 小さい要素の閾値を求める\n",
    "                threshold = torch.kthvalue(flat, k).values\n",
    "                mask = (W.abs() > threshold).float()\n",
    "                W = W * mask  # 枝刈りした重み\n",
    "        # 通常の線形変換\n",
    "        return F.linear(input, W, self.bias)\n",
    "    \n",
    "def replace_linear_with_prunedlinear(module, prune_ratio=0.2):\n",
    "    \"\"\"\n",
    "    モデル内の nn.Linear を PrunedLinear に置き換える\n",
    "    prune_ratio: 枝刈りする割合 (0.2 なら全重みの20%をゼロ化)\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, PrunedLinear):\n",
    "            continue\n",
    "        if isinstance(child, nn.Linear):\n",
    "            plinear = PrunedLinear(\n",
    "                child.in_features,\n",
    "                child.out_features,\n",
    "                bias=(child.bias is not None),\n",
    "                prune_ratio=prune_ratio\n",
    "            )\n",
    "            # 重みとバイアスをコピー\n",
    "            plinear.weight.data.copy_(child.weight.data)\n",
    "            if child.bias is not None:\n",
    "                plinear.bias.data.copy_(child.bias.data)\n",
    "            setattr(module, name, plinear)\n",
    "        else:\n",
    "            replace_linear_with_prunedlinear(child, prune_ratio=prune_ratio)\n",
    "    return module\n",
    "\n",
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = SimpleModel().to(device)\n",
    "# 通常学習\n",
    "print('warming up by no-quantized training...')\n",
    "model = train(model, lr=0.1, epochs=5, device=device)\n",
    "# Linear層をQuantizedLinearに置換\n",
    "model_p = replace_linear_with_prunedlinear(model, prune_ratio=0.8)\n",
    "print('pruning...')\n",
    "model_p = train(model_p, lr=1e-3, epochs=5, device=device)\n",
    "accuracy = compute_accuracy(model_p, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6215e2a",
   "metadata": {},
   "source": [
    "## 枝刈りと量子化の同時実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SymQuantSTE(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input: torch.Tensor, scale: torch.Tensor, num_bits: int):\n",
    "        if num_bits == 1:\n",
    "            s = scale.abs()\n",
    "            output = s * torch.sign(input)\n",
    "        else:\n",
    "            s = scale.abs().clamp_min(1e-8)\n",
    "            qmax = 2 ** (num_bits - 1) - 1\n",
    "            q = torch.clamp(torch.round(input / s), -qmax, qmax)\n",
    "            output = q * s\n",
    "\n",
    "        # backward用に保存\n",
    "        ctx.save_for_backward(input, s)\n",
    "        ctx.num_bits = num_bits\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, s = ctx.saved_tensors\n",
    "        num_bits = ctx.num_bits\n",
    "        if num_bits == 1:\n",
    "            grad_input = torch.clamp(grad_output, -1, 1)\n",
    "        else:\n",
    "            qmax = 2 ** (num_bits - 1) - 1\n",
    "            mask = (input.abs() <= qmax * s).to(grad_output.dtype)\n",
    "            grad_input = grad_output * mask\n",
    "        return grad_input, None, None\n",
    "\n",
    "\n",
    "class PrunedQuantLinear(nn.Linear):\n",
    "    \"\"\"\n",
    "    枝刈り + 量子化付き Linear 層\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 weight_bits=8, act_bits=None, prune_ratio=0.0):\n",
    "        super().__init__(in_features, out_features, bias)\n",
    "        self.weight_bits = weight_bits\n",
    "        self.act_bits = act_bits\n",
    "        self.prune_ratio = prune_ratio  # 0.0～1.0の割合\n",
    "\n",
    "    def forward(self, input):\n",
    "        # --- 枝刈り ---\n",
    "        if self.prune_ratio > 0:\n",
    "            # 重みの絶対値に基づいて閾値を決める\n",
    "            k = int(self.weight.numel() * self.prune_ratio)\n",
    "            if k > 0:\n",
    "                threshold = torch.topk(self.weight.abs().flatten(), k, largest=False).values.max()\n",
    "                mask = (self.weight.abs() > threshold).to(self.weight.dtype)\n",
    "                pruned_weight = self.weight * mask\n",
    "            else:\n",
    "                pruned_weight = self.weight\n",
    "        else:\n",
    "            pruned_weight = self.weight\n",
    "\n",
    "        # --- weight のスケール ---\n",
    "        if self.weight_bits == 1:\n",
    "            weight_scale = pruned_weight.abs().sum() / pruned_weight.numel()\n",
    "        else:\n",
    "            qmax_w = 2 ** (self.weight_bits - 1) - 1\n",
    "            weight_scale = (pruned_weight.max() - pruned_weight.min()) / (2 * qmax_w)\n",
    "\n",
    "        # --- activation のスケール ---\n",
    "        if self.act_bits is not None:\n",
    "            if self.act_bits == 1:\n",
    "                act_scale = input.abs().sum() / input.numel()\n",
    "            else:\n",
    "                qmax_a = 2 ** (self.act_bits - 1) - 1\n",
    "                act_scale = (input.max() - input.min()) / (2 * qmax_a)\n",
    "            input = SymQuantSTE.apply(input, act_scale, self.act_bits)\n",
    "\n",
    "        # --- quantized weight ---\n",
    "        w_q = SymQuantSTE.apply(pruned_weight, weight_scale, self.weight_bits)\n",
    "\n",
    "        return F.linear(input, w_q, self.bias)\n",
    "\n",
    "\n",
    "def replace_linear_with_prunedquantlinear(module, weight_bits=8, act_bits=None, prune_ratio=0.2):\n",
    "    \"\"\"\n",
    "    モデル内の nn.Linear を PrunedQuantLinear に置き換える\n",
    "    weight_bits: 重みの量子化ビット数\n",
    "    act_bits: 活性化の量子化ビット数 (Noneなら非量子化)\n",
    "    prune_ratio: 枝刈り割合 (0.2 なら全重みの20%をゼロ化)\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        # すでに PrunedQuantLinear ならスキップ\n",
    "        if isinstance(child, PrunedQuantLinear):\n",
    "            continue\n",
    "        if isinstance(child, nn.Linear):\n",
    "            pqlinear = PrunedQuantLinear(\n",
    "                child.in_features,\n",
    "                child.out_features,\n",
    "                bias=(child.bias is not None),\n",
    "                weight_bits=weight_bits,\n",
    "                act_bits=act_bits,\n",
    "                prune_ratio=prune_ratio\n",
    "            )\n",
    "            # 重みとバイアスをコピー\n",
    "            pqlinear.weight.data.copy_(child.weight.data)\n",
    "            if child.bias is not None:\n",
    "                pqlinear.bias.data.copy_(child.bias.data)\n",
    "            setattr(module, name, pqlinear)\n",
    "        else:\n",
    "            # 再帰的に探索\n",
    "            replace_linear_with_prunedquantlinear(child, weight_bits=weight_bits, act_bits=act_bits, prune_ratio=prune_ratio)\n",
    "    return module\n",
    "\n",
    "\n",
    "# モデルのインスタンスを作成\n",
    "model = SimpleModel().to(device)\n",
    "# 通常学習\n",
    "print('warming up by no-quantized training...')\n",
    "model = train(model, lr=0.1, epochs=5, device=device)\n",
    "# Linear層をQuantizedLinearに置換\n",
    "model_pq = replace_linear_with_prunedquantlinear(model, weight_bits=1, act_bits=8, prune_ratio=0.5)\n",
    "print('pruning...')\n",
    "model_pq = train(model_pq, lr=1e-3, epochs=5, device=device)\n",
    "accuracy = compute_accuracy(model_pq, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf083a",
   "metadata": {},
   "source": [
    "## 課題\n",
    "### ・アクティベーションのビット幅・重みのビット幅をそれぞれ変化させた時の精度変化を観察し、感度の違いを評価する\n",
    "### ・低ビットでもより高精度を達成するためには量子化パラメータをどのように設定するといいかを考察・実験してみる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
