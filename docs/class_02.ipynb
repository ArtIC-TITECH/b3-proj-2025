{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdiklpJlCy2d"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ArtIC-TITECH/b3-proj-2025/blob/main/docs/class_02.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RMa249PSwUy"
      },
      "source": [
        "# 本日の内容"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N8a-GF9UBhC"
      },
      "source": [
        "## 目次\n",
        "1. 過学習について\n",
        "1. パラメータの数え方\n",
        "1. モデルの軽量化\n",
        "  - 量子化\n",
        "  - 枝刈り\n",
        "  - 行列分解\n",
        "4. テーマの割り当て"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuKn0_fRTJX4"
      },
      "source": [
        "## 1. 過学習について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yODd3bEHUGqI"
      },
      "source": [
        "### 1-0.ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3t0CKaLKbtf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED7d2xjAUQhv"
      },
      "source": [
        "### 1-1.データセットの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oiy3BkBDP8-G"
      },
      "outputs": [],
      "source": [
        "# 普通のtransform (変更可能)\n",
        "transform_normal = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# テストデータには普通のtransformを使ってください\n",
        "transform_for_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_normal)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_for_test)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nNHORhqUZpJ"
      },
      "source": [
        "### 1-2.モデルの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twQemZAhP-jA"
      },
      "outputs": [],
      "source": [
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self): # モデルのセットアップ\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x): # モデルが行う処理\n",
        "        x = x.view(-1, 28 * 28)  # 28x28の画像を１次元に変換\n",
        "        x = self.fc1(x) # ベクトルサイズを28x28から128へ\n",
        "        x = nn.ReLU()(x) # 活性化関数\n",
        "        x = self.fc2(x) # ベクトルサイズを128から128へ\n",
        "        x = nn.ReLU()(x) # 活性化関数\n",
        "        x = self.fc3(x) # ベクトルサイズを128から10へ\n",
        "        return x\n",
        "\n",
        "# モデルのインスタンスを作成\n",
        "model = SimpleModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGR_5xOxUgJl"
      },
      "source": [
        "### 1-3. 損失関数, 最適化関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP99AepDQADz"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# 変更可能\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zXwjKwGUml2"
      },
      "source": [
        "### 1-4. モデルの学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evX9NQ_QUoGb"
      },
      "source": [
        "モデルを30エポック訓練します。  \n",
        "各エポックでの訓練損失, テスト損失, 訓練精度, テスト精度を取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xT9a4qAWjacF",
        "outputId": "cfa5aea8-2341-4f57-ccb3-e94f876de106"
      },
      "outputs": [],
      "source": [
        "# エポック数\n",
        "epochs = 30\n",
        "\n",
        "# 訓練とテストの損失・精度を記録するリスト\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # 訓練フェーズ\n",
        "    model.train()  # 訓練モード\n",
        "    loss_sum = 0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        # モデルの予測\n",
        "        outputs = model(images)\n",
        "        # 損失の計算\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_sum += loss.item()\n",
        "        # 勾配の初期化\n",
        "        optimizer.zero_grad()\n",
        "        # バックプロパゲーション\n",
        "        loss.backward()\n",
        "        # オプティマイザの更新\n",
        "        optimizer.step()\n",
        "        # 精度の計算\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    # 訓練損失と訓練精度\n",
        "    avg_train_loss = loss_sum / len(train_loader)\n",
        "    train_loss = avg_train_loss\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "    # テストフェーズ\n",
        "    model.eval()  # 評価モード\n",
        "    loss_sum_test = 0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss_sum_test += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "    # テスト損失とテスト精度\n",
        "    avg_test_loss = loss_sum_test / len(test_loader)\n",
        "    test_loss = avg_test_loss\n",
        "    test_accuracy = 100 * correct_test / total_test\n",
        "\n",
        "    # 訓練とテストの損失・精度をリストに保存\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    test_accuracies.append(test_accuracy)\n",
        "\n",
        "    # 損失と精度を表示\n",
        "    print(f'Epoch [{epoch+1}/{epochs}]')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnYGFERmVZsm"
      },
      "source": [
        "### 1-5. 過学習について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFX8GPTFVsDX"
      },
      "source": [
        "以下のセルは各エポックでの訓練損失, テスト損失, 訓練精度, テスト精度をプロットするものです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "TVR4OTZAjTQI",
        "outputId": "ce57a27b-9db5-4026-85c5-70d9dd757b64"
      },
      "outputs": [],
      "source": [
        "# 訓練とテストの損失をプロット\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# 損失のプロット\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(epochs), train_losses, label='Train Loss')\n",
        "plt.plot(range(epochs), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train vs Test Loss')\n",
        "plt.legend()\n",
        "\n",
        "# 精度のプロット\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(epochs), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(epochs), test_accuracies, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Train vs Test Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# プロットを表示\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjR5yQd1WRFb"
      },
      "source": [
        "左がLossで右が精度です。  \n",
        "訓練(青)とテスト(オレンジ)を比較するとLossも精度も訓練(青)のほうが良好です。  \n",
        "この差は過学習によるものです。過学習はモデルが訓練データに適合しすぎる現象です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vN7MXrCYKxZ"
      },
      "source": [
        "## 2. パラメータの数え方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBd4fpxfYx1I"
      },
      "source": [
        "### 2-0.ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POWMDff7YKQB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJyePQgPY22F"
      },
      "source": [
        "### 2-1.モデルの定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T05t5s97ZjEs"
      },
      "source": [
        "前回、線形関数の近似で使った$y=wx+b$を使います。  \n",
        "この関数で学習可能なパラメータは$w$と$b$の2つです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tp4aoEMX8gH"
      },
      "outputs": [],
      "source": [
        "# モデルの定義\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(1, 1)  # 入力1、出力1の線形層\n",
        "        init.constant_(self.linear.weight, 0)  # 重みwをすべて0に初期化\n",
        "        init.constant_(self.linear.bias, 0)    # バイアスbをすべて0に初期化\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# モデルのインスタンスを作成\n",
        "model = LinearRegressionModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A57F3-Jfavw_"
      },
      "source": [
        "### 2-2. パラメータの数え方"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMVgt_GLaZ0x"
      },
      "source": [
        "学習可能なパラメータ$w$と$b$はmodel.parameters()によってアクセスできます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gY8TKEZaDnR",
        "outputId": "cc7e81b7-a4fc-43ba-f1bf-d54e93ae5eed"
      },
      "outputs": [],
      "source": [
        "for p in model.parameters():\n",
        "  print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kobcxO6aoS5"
      },
      "source": [
        "パラメータ数は以下のようにカウントできます。  \n",
        "numelは\"number of elements\"(要素数)の略です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Bd-68OaLLX",
        "outputId": "9130b442-68a1-4716-c1af-a21fcfb4f970"
      },
      "outputs": [],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "num_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya8GrqRpa7RO"
      },
      "source": [
        "### 2-3. nn.Linearのパラメータ数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fa9QrBMbHUH"
      },
      "source": [
        "最後にnn.Linear(入力サイズ, 出力サイズ)のパラメータ数について説明します。  \n",
        "nn.Linearは(出力サイズ$\\times$入力サイズ)の重み行列$\\mathbf{W}$と(出力サイズ)のバイアスベクトル$b$を生成します。   \n",
        "したがって、パラメータ数は  \n",
        "```\n",
        "出力サイズ×入力サイズ+出力サイズ  \n",
        "```\n",
        "で計算できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMI53iVAamj9",
        "outputId": "308c91e9-9916-4bde-aa78-65fcdf21bcdf"
      },
      "outputs": [],
      "source": [
        "# 入力チャンネル数と出力チャンネル数を指定して線形層を作成\n",
        "input_channels = 5\n",
        "output_channels = 3\n",
        "linear_layer = nn.Linear(input_channels, output_channels)\n",
        "\n",
        "# パラメータ数を計算\n",
        "num_params = sum(p.numel() for p in linear_layer.parameters())\n",
        "\n",
        "print(f\"nn.Linear({input_channels}, {output_channels}) のパラメータ数: {num_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oskvex-1eyfB"
      },
      "source": [
        "## 3. モデルの軽量化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_YHIuAhgBM3"
      },
      "source": [
        "ChatGPTに代表される大規模言語モデルは大量のパラメータを持っています。  \n",
        "例えば、Llama 7Bは約70億のパラメータを持ち、32ビット浮動小数点数で保存すると、約28GBのメモリが必要です。  \n",
        "今回は、モデルの軽量化技術として\n",
        "- パラメータを低ビットで表現する量子化\n",
        "- 一部パラメータを0にする枝刈り\n",
        "\n",
        "について紹介します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDF8pwM2heKe"
      },
      "source": [
        "### 3-1. 量子化について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHK0kqtshpGW"
      },
      "source": [
        "ライブラリのimport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBP-90DRhoLA"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZzOHTOBh0ZJ"
      },
      "source": [
        "今回は4つの要素を持つテンソルを量子化します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23abQWyGe0QD",
        "outputId": "9461c527-30f5-46fe-a2b9-5a5b3f22482e"
      },
      "outputs": [],
      "source": [
        "# 4つの要素を持つ乱数で初期化したテンソルを作成\n",
        "original_tensor = torch.rand(4)  # 0から1の範囲の一様分布で初期化\n",
        "print(\"量子化するテンソル:\", original_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C04hlI9yjVSh"
      },
      "source": [
        "今回はmin-maxスケーリングと呼ばれる量子化について説明します。  \n",
        "min-maxスケーリングは最小値と最大値を基に、データを指定した範囲にスケーリングします。  \n",
        "コードの例は8bit量子化(0~255)を行います。\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ArtIC-TITECH/b3-proj-2024/refs/heads/main/resources/class_01/quant_asym.png\" width=\"50%\">\n",
        "\n",
        "min-maxスケーリングのアルゴリズム\n",
        "1. 最小値を0にするためにテンソルをminでひく。\n",
        "1. 0~255の範囲にするためにテンソルに255/(max-min)を乗算する。\n",
        "1. 整数化する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsnniklRe_SZ",
        "outputId": "53c2c62a-1961-47ce-8956-93fc47db5092"
      },
      "outputs": [],
      "source": [
        "# 最大値と最小値の取得\n",
        "tensor_max = original_tensor.max()\n",
        "tensor_min = original_tensor.min()\n",
        "\n",
        "# 量子化\n",
        "# テンソルをminでひく\n",
        "quantized_tensor = original_tensor - tensor_min\n",
        "# テンソルに255/(max-min)を乗算する\n",
        "quantized_tensor = quantized_tensor * 255 / (tensor_max-tensor_min)\n",
        "# 整数化する\n",
        "quantized_tensor = quantized_tensor.round().clamp(0, 255).int()\n",
        "print(\"量子化されたテンソル:\", quantized_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5ihj4a_nvTb"
      },
      "source": [
        "int32とありますが0から255の範囲です。  \n",
        "量子化と反対の操作をすることでオリジナルのテンソルに近いテンソルが得られます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1qz2bZYlvK0",
        "outputId": "7bf81a1d-7092-4d0f-8977-bf32212f2e74"
      },
      "outputs": [],
      "source": [
        "# 復元\n",
        "dequantized_tensor = quantized_tensor.float() * (tensor_max-tensor_min) / 255\n",
        "dequantized_tensor = dequantized_tensor + tensor_min\n",
        "print(\"オリジナルのテンソル:\", original_tensor)\n",
        "print(\"復元されたテンソル:\", dequantized_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### ※補足：ベクトル量子化\n",
        "\n",
        "ベクトル量子化は、１つの要素を整数値に丸めるのではなく、ベクトル全体を代表ベクトルで置き換えてインデックスで表現します。\n",
        "代表ベクトルの求め方は、k-meansクラスタリングアルゴリズムで求めることが一般的です。\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ArtIC-TITECH/b3-proj-2025/refs/heads/main/resources/class_02/k-means.png\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# 乱数で初期化されたテンソル\n",
        "tensor = torch.randn(8, 8)\n",
        "print(\"オリジナルのテンソル:\\n\", tensor)\n",
        "\n",
        "# --- K-means でベクトル量子化 ---\n",
        "# 各行をクラスタリング対象とする\n",
        "X = tensor.numpy()\n",
        "\n",
        "# クラスタ数を指定 (例: 3 クラスタ)\n",
        "k = 3\n",
        "kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\").fit(X)\n",
        "\n",
        "# 各行を対応するクラスタ中心に置き換え\n",
        "X_quantized = kmeans.cluster_centers_[kmeans.labels_]\n",
        "\n",
        "tensor_vq = torch.tensor(X_quantized, dtype=torch.float32)\n",
        "\n",
        "print(\"\\nK-means (k={}) 量子化後のテンソル:\\n\".format(k), tensor_vq)\n",
        "\n",
        "# --- 誤差（Frobeniusノルム）---\n",
        "error = torch.norm(tensor - tensor_vq)\n",
        "print(\"\\n量子化誤差 (Frobenius norm):\", error.item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7FUvVQwrkpl"
      },
      "source": [
        "### 3-2. 枝刈りについて"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YQ47YJfrgLJ"
      },
      "source": [
        "枝刈りは計算への影響が小さい要素を0にする処理です。  \n",
        "今回は8つの要素を持つテンソルのうち、絶対値が小さい要素を0にする処理を実装します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSU6iWKCo3D2"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ArtIC-TITECH/b3-proj-2024/refs/heads/main/resources/class_01/pruning.svg\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPiaCoc4nNCE",
        "outputId": "222e9be6-8b0f-4945-c8ed-0be8f80776f1"
      },
      "outputs": [],
      "source": [
        "# 乱数で初期化されたテンソルを作成\n",
        "tensor = torch.randn(8)\n",
        "print(\"オリジナルのテンソル:\", tensor)\n",
        "\n",
        "# プルーニングする個数\n",
        "num_prune = 2\n",
        "\n",
        "# num_prune番目に小さい絶対値をスレッショルドに\n",
        "threshold = torch.topk(tensor.abs(), num_prune, largest=False).values[-1]\n",
        "\n",
        "# 絶対値が小さい要素をプルーニング\n",
        "pruned_tensor = tensor.clone()\n",
        "pruned_tensor[torch.abs(pruned_tensor) <= threshold] = 0\n",
        "\n",
        "print(\"プルーニングされたテンソル:\", pruned_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3-3. 行列分解の低ランク近似について\n",
        "行列分解は行列を２つの行列積に分解する処理です。  \n",
        "主な行列分解の１つに特異値分解があり、特異値の大きい順にtop-kを選んで２つの小さい行列に分解すると最適な低ランク近似が得られます。\n",
        "元の行列のパラメータ数より分解後の行列のパラメータ数の方が少ないように近似すれば圧縮になります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ArtIC-TITECH/b3-proj-2025/refs/heads/main/resources/class_02/SVD.jpg\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# 乱数で初期化されたテンソル\n",
        "tensor = torch.randn(8, 8)\n",
        "print(\"オリジナルのテンソル:\\n\", tensor)\n",
        "\n",
        "# SVD分解\n",
        "U, S, Vh = torch.linalg.svd(tensor)\n",
        "\n",
        "# ランク k の近似を作成 (例: k=2)\n",
        "k = 4\n",
        "Uk = U[:, :k]\n",
        "Sk = torch.diag(S[:k])\n",
        "Vk = Vh[:k, :]\n",
        "\n",
        "tensor_approx = Uk @ Sk @ Vk\n",
        "\n",
        "print(\"\\nランク\", k, \"での近似:\\n\", tensor_approx)\n",
        "\n",
        "# 誤差（フロベニウスノルム）\n",
        "error = torch.norm(tensor - tensor_approx)\n",
        "print(\"\\n近似誤差 (Frobenius norm):\", error.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaEQvQJ5vIaT"
      },
      "source": [
        "## 4. オートエンコーダについて"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4FLPtSkxmC_"
      },
      "source": [
        "オートエンコーダは入力されたものを出力するように訓練したニューラルネットワークです。  \n",
        "オートエンコーダは情報を圧縮する「エンコーダ」と圧縮された情報を復元する「デコーダ」からなります。  \n",
        "今回はオートエンコーダを使って2つの画像の中間画像を生成する処理を実装します。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7WMpKpMxKDh"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/ArtIC-TITECH/b3-proj-2024/refs/heads/main/resources/class_01/chainer_sda_pic2.jpg\" width=\"50%\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6AthYUfykjv"
      },
      "source": [
        "### 4-0.ライブラリのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bFZRVt4xOoR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrQpTlGgy-as"
      },
      "source": [
        "### 4-1.データセットの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTMlia1Mytm5"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))  # 28x28画像をベクトルに変換\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfzugCfozGAz"
      },
      "source": [
        "### 4-2.モデルの作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWqnbyriypQI"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "\n",
        "        # エンコーダ\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28 * 28, 128),  # 画像サイズ28x28を128次元に圧縮\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64),       # さらに64次元に圧縮\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32)         # 潜在空間32次元\n",
        "        )\n",
        "\n",
        "        # デコーダ\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(32, 64),        # 潜在空間から64次元へ\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 128),       # 128次元に拡張\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28 * 28),  # 元の画像サイズ28x28に復元\n",
        "            nn.Sigmoid()              # 出力を0-1に正規化\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        return self.decoder(z)\n",
        "\n",
        "model = Autoencoder()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsSjd4L7zUcP"
      },
      "source": [
        "###4-3. 損失関数, 最適化関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QPW1gApyrcO"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBTko1VKzcAb"
      },
      "source": [
        "### 4-4. モデルの学習"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xPmcVGmzrQI",
        "outputId": "1e7394de-d310-4095-a033-9f82652f98b0"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for data in train_loader:\n",
        "        inputs, _ = data\n",
        "        inputs = inputs\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, inputs)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80x9H8phze_o"
      },
      "source": [
        "### 4-5. 中間画像の生成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DDNNcNg80KpY",
        "outputId": "f7c5750f-ce66-4d36-bc16-15a649c88ac9"
      },
      "outputs": [],
      "source": [
        "# サンプルの手書き数字画像を2つ選びます（インデックスを指定）\n",
        "index1, index2 = 900, 1000\n",
        "img1, _ = train_dataset[index1]\n",
        "img2, _ = train_dataset[index2]\n",
        "\n",
        "# 画像を表示する\n",
        "fig, axes = plt.subplots(1, 2, figsize=(5, 5))\n",
        "axes[0].imshow(img1.view(28, 28), cmap='gray')\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('Image 1')\n",
        "\n",
        "axes[1].imshow(img2.view(28, 28), cmap='gray')\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('Image 2')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "w-_xfxlGyxht",
        "outputId": "b9f8f8be-28cb-4c34-f060-e799c7368ae4"
      },
      "outputs": [],
      "source": [
        "# 画像をベクトルに変換\n",
        "img1 = img1.view(1, -1)\n",
        "img2 = img2.view(1, -1)\n",
        "\n",
        "# 潜在空間へのエンコード\n",
        "z1 = model.encoder(img1)\n",
        "z2 = model.encoder(img2)\n",
        "\n",
        "# 0〜1の範囲で内挿\n",
        "num_interpolations = 10\n",
        "interpolated_images = []\n",
        "alphas = np.linspace(0, 1, num_interpolations)\n",
        "\n",
        "fig, axes = plt.subplots(1, num_interpolations, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes):\n",
        "    z_interpolated = (1 - alphas[i]) * z1 + alphas[i] * z2\n",
        "    img_interpolated = model.decoder(z_interpolated).view(28, 28).cpu().detach().numpy()\n",
        "    ax.imshow(img_interpolated, cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "    # alphaの値を画像の下に表示\n",
        "    ax.text(0.5, -0.1, f'α = {alphas[i]:.2f}', ha='center', va='center', transform=ax.transAxes)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bk71VFuHzEUj"
      },
      "source": [
        "## 5. テーマの割り当て"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOyGRBqtzLNE"
      },
      "source": [
        "テーマA：最適化関数におけるMomentumの評価  \n",
        "テーマB：学習率とバッチサイズの精度への影響評価  \n",
        "テーマC：枝刈りによるモデルの性能低下の評価  \n",
        "テーマD：量子化パラメータのモデル性能への影響  \n",
        "テーマE：オートエンコーダによる画像のデノイジング  \n",
        "テーマF：モデルの敵対的サンプルへの耐性評価  \n",
        "テーマG：オートエンコーダを使った異常検知の分析  \n",
        "テーマH：リプレイメモリによるモデルの忘却防止評価  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
